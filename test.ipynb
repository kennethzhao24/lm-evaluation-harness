{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/youpengzhao/anaconda3/envs/nlp/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2022-12-18 21:57:33.713293: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-18 21:57:34.304112: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11/lib64:\n",
      "2022-12-18 21:57:34.304198: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11/lib64:\n",
      "2022-12-18 21:57:34.304204: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from lm_eval.models.opt_models.opt_pytorch import OPTForCausalLM\n",
    "from transformers import AutoConfig, PreTrainedTokenizerFast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='facebook/opt-125m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = AutoConfig.from_pretrained(model_name)\n",
    "config.vocab_size = 50277"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OPTConfig {\n",
       "  \"_name_or_path\": \"facebook/opt-125m\",\n",
       "  \"_remove_final_layer_norm\": false,\n",
       "  \"activation_dropout\": 0.0,\n",
       "  \"activation_function\": \"relu\",\n",
       "  \"architectures\": [\n",
       "    \"OPTForCausalLM\"\n",
       "  ],\n",
       "  \"attention_dropout\": 0.0,\n",
       "  \"bos_token_id\": 2,\n",
       "  \"do_layer_norm_before\": true,\n",
       "  \"dropout\": 0.1,\n",
       "  \"enable_bias\": true,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"ffn_dim\": 3072,\n",
       "  \"hidden_size\": 768,\n",
       "  \"init_std\": 0.02,\n",
       "  \"layer_norm_elementwise_affine\": true,\n",
       "  \"layerdrop\": 0.0,\n",
       "  \"max_position_embeddings\": 2048,\n",
       "  \"model_type\": \"opt\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 1,\n",
       "  \"prefix\": \"</s>\",\n",
       "  \"torch_dtype\": \"float16\",\n",
       "  \"transformers_version\": \"4.25.1\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 50277,\n",
       "  \"word_embed_proj_dim\": 768\n",
       "}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = OPTForCausalLM(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.save(opt.state_dict(), 'test_opt.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.load_state_dict(ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/youpengzhao/anaconda3/envs/nlp/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2022-12-18 22:24:26.160865: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-18 22:24:26.740121: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11/lib64:\n",
      "2022-12-18 22:24:26.740207: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11/lib64:\n",
      "2022-12-18 22:24:26.740213: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from lm_eval.models.opt_models.dynamic_opt import OPTForCausalLM\n",
    "import json\n",
    "from types import SimpleNamespace\n",
    "\n",
    "config_file='/home/youpengzhao/code/lm-evaluation-harness/lm_eval/models/config.json'\n",
    "\n",
    "with open(config_file) as f:\n",
    "    data = json.loads(f.read())\n",
    "config = SimpleNamespace(**data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.vocab_size = 50277"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = OPTForCausalLM(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "pretrained = '/home/youpengzhao/code/opt_60000.pth'\n",
    "ckpt = torch.load(pretrained, map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "def check_for_weight_keys(ckpt):\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in ckpt.items():\n",
    "        if k[:6] == 'module':               \n",
    "            name = k[7:] # remove `module.`\n",
    "        else:\n",
    "            name = k\n",
    "        new_state_dict[name] = v\n",
    "    return new_state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = check_for_weight_keys(ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.load_state_dict(ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-19 10:35:35.976756: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-19 10:35:36.553147: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11/lib64:\n",
      "2023-03-19 10:35:36.553248: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11/lib64:\n",
      "2023-03-19 10:35:36.553254: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import transformers\n",
    "\n",
    "config = transformers.AutoConfig.from_pretrained('gpt2')\n",
    "config.vocab_size = 50277\n",
    "config.pad_token_id = 1\n",
    "gpt2 = transformers.AutoModelForCausalLM.from_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = torch.load('/home/youpengzhao/code/pretrained/GPT2/gpt_final.pth', map_location='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['transformer.wte.weight', 'transformer.wpe.weight', 'transformer.h.0.ln_1.weight', 'transformer.h.0.ln_1.bias', 'transformer.h.0.attn.bias', 'transformer.h.0.attn.masked_bias', 'transformer.h.0.attn.c_attn.weight', 'transformer.h.0.attn.c_attn.bias', 'transformer.h.0.attn.c_proj.weight', 'transformer.h.0.attn.c_proj.bias', 'transformer.h.0.ln_2.weight', 'transformer.h.0.ln_2.bias', 'transformer.h.0.mlp.c_fc.weight', 'transformer.h.0.mlp.c_fc.bias', 'transformer.h.0.mlp.c_proj.weight', 'transformer.h.0.mlp.c_proj.bias', 'transformer.h.1.ln_1.weight', 'transformer.h.1.ln_1.bias', 'transformer.h.1.attn.bias', 'transformer.h.1.attn.masked_bias', 'transformer.h.1.attn.c_attn.weight', 'transformer.h.1.attn.c_attn.bias', 'transformer.h.1.attn.c_proj.weight', 'transformer.h.1.attn.c_proj.bias', 'transformer.h.1.ln_2.weight', 'transformer.h.1.ln_2.bias', 'transformer.h.1.mlp.c_fc.weight', 'transformer.h.1.mlp.c_fc.bias', 'transformer.h.1.mlp.c_proj.weight', 'transformer.h.1.mlp.c_proj.bias', 'transformer.h.2.ln_1.weight', 'transformer.h.2.ln_1.bias', 'transformer.h.2.attn.bias', 'transformer.h.2.attn.masked_bias', 'transformer.h.2.attn.c_attn.weight', 'transformer.h.2.attn.c_attn.bias', 'transformer.h.2.attn.c_proj.weight', 'transformer.h.2.attn.c_proj.bias', 'transformer.h.2.ln_2.weight', 'transformer.h.2.ln_2.bias', 'transformer.h.2.mlp.c_fc.weight', 'transformer.h.2.mlp.c_fc.bias', 'transformer.h.2.mlp.c_proj.weight', 'transformer.h.2.mlp.c_proj.bias', 'transformer.h.3.ln_1.weight', 'transformer.h.3.ln_1.bias', 'transformer.h.3.attn.bias', 'transformer.h.3.attn.masked_bias', 'transformer.h.3.attn.c_attn.weight', 'transformer.h.3.attn.c_attn.bias', 'transformer.h.3.attn.c_proj.weight', 'transformer.h.3.attn.c_proj.bias', 'transformer.h.3.ln_2.weight', 'transformer.h.3.ln_2.bias', 'transformer.h.3.mlp.c_fc.weight', 'transformer.h.3.mlp.c_fc.bias', 'transformer.h.3.mlp.c_proj.weight', 'transformer.h.3.mlp.c_proj.bias', 'transformer.h.4.ln_1.weight', 'transformer.h.4.ln_1.bias', 'transformer.h.4.attn.bias', 'transformer.h.4.attn.masked_bias', 'transformer.h.4.attn.c_attn.weight', 'transformer.h.4.attn.c_attn.bias', 'transformer.h.4.attn.c_proj.weight', 'transformer.h.4.attn.c_proj.bias', 'transformer.h.4.ln_2.weight', 'transformer.h.4.ln_2.bias', 'transformer.h.4.mlp.c_fc.weight', 'transformer.h.4.mlp.c_fc.bias', 'transformer.h.4.mlp.c_proj.weight', 'transformer.h.4.mlp.c_proj.bias', 'transformer.h.5.ln_1.weight', 'transformer.h.5.ln_1.bias', 'transformer.h.5.attn.bias', 'transformer.h.5.attn.masked_bias', 'transformer.h.5.attn.c_attn.weight', 'transformer.h.5.attn.c_attn.bias', 'transformer.h.5.attn.c_proj.weight', 'transformer.h.5.attn.c_proj.bias', 'transformer.h.5.ln_2.weight', 'transformer.h.5.ln_2.bias', 'transformer.h.5.mlp.c_fc.weight', 'transformer.h.5.mlp.c_fc.bias', 'transformer.h.5.mlp.c_proj.weight', 'transformer.h.5.mlp.c_proj.bias', 'transformer.h.6.ln_1.weight', 'transformer.h.6.ln_1.bias', 'transformer.h.6.attn.bias', 'transformer.h.6.attn.masked_bias', 'transformer.h.6.attn.c_attn.weight', 'transformer.h.6.attn.c_attn.bias', 'transformer.h.6.attn.c_proj.weight', 'transformer.h.6.attn.c_proj.bias', 'transformer.h.6.ln_2.weight', 'transformer.h.6.ln_2.bias', 'transformer.h.6.mlp.c_fc.weight', 'transformer.h.6.mlp.c_fc.bias', 'transformer.h.6.mlp.c_proj.weight', 'transformer.h.6.mlp.c_proj.bias', 'transformer.h.7.ln_1.weight', 'transformer.h.7.ln_1.bias', 'transformer.h.7.attn.bias', 'transformer.h.7.attn.masked_bias', 'transformer.h.7.attn.c_attn.weight', 'transformer.h.7.attn.c_attn.bias', 'transformer.h.7.attn.c_proj.weight', 'transformer.h.7.attn.c_proj.bias', 'transformer.h.7.ln_2.weight', 'transformer.h.7.ln_2.bias', 'transformer.h.7.mlp.c_fc.weight', 'transformer.h.7.mlp.c_fc.bias', 'transformer.h.7.mlp.c_proj.weight', 'transformer.h.7.mlp.c_proj.bias', 'transformer.h.8.ln_1.weight', 'transformer.h.8.ln_1.bias', 'transformer.h.8.attn.bias', 'transformer.h.8.attn.masked_bias', 'transformer.h.8.attn.c_attn.weight', 'transformer.h.8.attn.c_attn.bias', 'transformer.h.8.attn.c_proj.weight', 'transformer.h.8.attn.c_proj.bias', 'transformer.h.8.ln_2.weight', 'transformer.h.8.ln_2.bias', 'transformer.h.8.mlp.c_fc.weight', 'transformer.h.8.mlp.c_fc.bias', 'transformer.h.8.mlp.c_proj.weight', 'transformer.h.8.mlp.c_proj.bias', 'transformer.h.9.ln_1.weight', 'transformer.h.9.ln_1.bias', 'transformer.h.9.attn.bias', 'transformer.h.9.attn.masked_bias', 'transformer.h.9.attn.c_attn.weight', 'transformer.h.9.attn.c_attn.bias', 'transformer.h.9.attn.c_proj.weight', 'transformer.h.9.attn.c_proj.bias', 'transformer.h.9.ln_2.weight', 'transformer.h.9.ln_2.bias', 'transformer.h.9.mlp.c_fc.weight', 'transformer.h.9.mlp.c_fc.bias', 'transformer.h.9.mlp.c_proj.weight', 'transformer.h.9.mlp.c_proj.bias', 'transformer.h.10.ln_1.weight', 'transformer.h.10.ln_1.bias', 'transformer.h.10.attn.bias', 'transformer.h.10.attn.masked_bias', 'transformer.h.10.attn.c_attn.weight', 'transformer.h.10.attn.c_attn.bias', 'transformer.h.10.attn.c_proj.weight', 'transformer.h.10.attn.c_proj.bias', 'transformer.h.10.ln_2.weight', 'transformer.h.10.ln_2.bias', 'transformer.h.10.mlp.c_fc.weight', 'transformer.h.10.mlp.c_fc.bias', 'transformer.h.10.mlp.c_proj.weight', 'transformer.h.10.mlp.c_proj.bias', 'transformer.h.11.ln_1.weight', 'transformer.h.11.ln_1.bias', 'transformer.h.11.attn.bias', 'transformer.h.11.attn.masked_bias', 'transformer.h.11.attn.c_attn.weight', 'transformer.h.11.attn.c_attn.bias', 'transformer.h.11.attn.c_proj.weight', 'transformer.h.11.attn.c_proj.bias', 'transformer.h.11.ln_2.weight', 'transformer.h.11.ln_2.bias', 'transformer.h.11.mlp.c_fc.weight', 'transformer.h.11.mlp.c_fc.bias', 'transformer.h.11.mlp.c_proj.weight', 'transformer.h.11.mlp.c_proj.bias', 'transformer.ln_f.weight', 'transformer.ln_f.bias', 'lm_head.weight'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt2.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['module.transformer.wte.weight', 'module.transformer.wpe.weight', 'module.transformer.h.0.ln_1.weight', 'module.transformer.h.0.ln_1.bias', 'module.transformer.h.0.attn.bias', 'module.transformer.h.0.attn.masked_bias', 'module.transformer.h.0.attn.c_attn.weight', 'module.transformer.h.0.attn.c_attn.bias', 'module.transformer.h.0.attn.c_proj.weight', 'module.transformer.h.0.attn.c_proj.bias', 'module.transformer.h.0.ln_2.weight', 'module.transformer.h.0.ln_2.bias', 'module.transformer.h.0.mlp.c_fc.weight', 'module.transformer.h.0.mlp.c_fc.bias', 'module.transformer.h.0.mlp.c_proj.weight', 'module.transformer.h.0.mlp.c_proj.bias', 'module.transformer.h.1.ln_1.weight', 'module.transformer.h.1.ln_1.bias', 'module.transformer.h.1.attn.bias', 'module.transformer.h.1.attn.masked_bias', 'module.transformer.h.1.attn.c_attn.weight', 'module.transformer.h.1.attn.c_attn.bias', 'module.transformer.h.1.attn.c_proj.weight', 'module.transformer.h.1.attn.c_proj.bias', 'module.transformer.h.1.ln_2.weight', 'module.transformer.h.1.ln_2.bias', 'module.transformer.h.1.mlp.c_fc.weight', 'module.transformer.h.1.mlp.c_fc.bias', 'module.transformer.h.1.mlp.c_proj.weight', 'module.transformer.h.1.mlp.c_proj.bias', 'module.transformer.h.2.ln_1.weight', 'module.transformer.h.2.ln_1.bias', 'module.transformer.h.2.attn.bias', 'module.transformer.h.2.attn.masked_bias', 'module.transformer.h.2.attn.c_attn.weight', 'module.transformer.h.2.attn.c_attn.bias', 'module.transformer.h.2.attn.c_proj.weight', 'module.transformer.h.2.attn.c_proj.bias', 'module.transformer.h.2.ln_2.weight', 'module.transformer.h.2.ln_2.bias', 'module.transformer.h.2.mlp.c_fc.weight', 'module.transformer.h.2.mlp.c_fc.bias', 'module.transformer.h.2.mlp.c_proj.weight', 'module.transformer.h.2.mlp.c_proj.bias', 'module.transformer.h.3.ln_1.weight', 'module.transformer.h.3.ln_1.bias', 'module.transformer.h.3.attn.bias', 'module.transformer.h.3.attn.masked_bias', 'module.transformer.h.3.attn.c_attn.weight', 'module.transformer.h.3.attn.c_attn.bias', 'module.transformer.h.3.attn.c_proj.weight', 'module.transformer.h.3.attn.c_proj.bias', 'module.transformer.h.3.ln_2.weight', 'module.transformer.h.3.ln_2.bias', 'module.transformer.h.3.mlp.c_fc.weight', 'module.transformer.h.3.mlp.c_fc.bias', 'module.transformer.h.3.mlp.c_proj.weight', 'module.transformer.h.3.mlp.c_proj.bias', 'module.transformer.h.4.ln_1.weight', 'module.transformer.h.4.ln_1.bias', 'module.transformer.h.4.attn.bias', 'module.transformer.h.4.attn.masked_bias', 'module.transformer.h.4.attn.c_attn.weight', 'module.transformer.h.4.attn.c_attn.bias', 'module.transformer.h.4.attn.c_proj.weight', 'module.transformer.h.4.attn.c_proj.bias', 'module.transformer.h.4.ln_2.weight', 'module.transformer.h.4.ln_2.bias', 'module.transformer.h.4.mlp.c_fc.weight', 'module.transformer.h.4.mlp.c_fc.bias', 'module.transformer.h.4.mlp.c_proj.weight', 'module.transformer.h.4.mlp.c_proj.bias', 'module.transformer.h.5.ln_1.weight', 'module.transformer.h.5.ln_1.bias', 'module.transformer.h.5.attn.bias', 'module.transformer.h.5.attn.masked_bias', 'module.transformer.h.5.attn.c_attn.weight', 'module.transformer.h.5.attn.c_attn.bias', 'module.transformer.h.5.attn.c_proj.weight', 'module.transformer.h.5.attn.c_proj.bias', 'module.transformer.h.5.ln_2.weight', 'module.transformer.h.5.ln_2.bias', 'module.transformer.h.5.mlp.c_fc.weight', 'module.transformer.h.5.mlp.c_fc.bias', 'module.transformer.h.5.mlp.c_proj.weight', 'module.transformer.h.5.mlp.c_proj.bias', 'module.transformer.h.6.ln_1.weight', 'module.transformer.h.6.ln_1.bias', 'module.transformer.h.6.attn.bias', 'module.transformer.h.6.attn.masked_bias', 'module.transformer.h.6.attn.c_attn.weight', 'module.transformer.h.6.attn.c_attn.bias', 'module.transformer.h.6.attn.c_proj.weight', 'module.transformer.h.6.attn.c_proj.bias', 'module.transformer.h.6.ln_2.weight', 'module.transformer.h.6.ln_2.bias', 'module.transformer.h.6.mlp.c_fc.weight', 'module.transformer.h.6.mlp.c_fc.bias', 'module.transformer.h.6.mlp.c_proj.weight', 'module.transformer.h.6.mlp.c_proj.bias', 'module.transformer.h.7.ln_1.weight', 'module.transformer.h.7.ln_1.bias', 'module.transformer.h.7.attn.bias', 'module.transformer.h.7.attn.masked_bias', 'module.transformer.h.7.attn.c_attn.weight', 'module.transformer.h.7.attn.c_attn.bias', 'module.transformer.h.7.attn.c_proj.weight', 'module.transformer.h.7.attn.c_proj.bias', 'module.transformer.h.7.ln_2.weight', 'module.transformer.h.7.ln_2.bias', 'module.transformer.h.7.mlp.c_fc.weight', 'module.transformer.h.7.mlp.c_fc.bias', 'module.transformer.h.7.mlp.c_proj.weight', 'module.transformer.h.7.mlp.c_proj.bias', 'module.transformer.h.8.ln_1.weight', 'module.transformer.h.8.ln_1.bias', 'module.transformer.h.8.attn.bias', 'module.transformer.h.8.attn.masked_bias', 'module.transformer.h.8.attn.c_attn.weight', 'module.transformer.h.8.attn.c_attn.bias', 'module.transformer.h.8.attn.c_proj.weight', 'module.transformer.h.8.attn.c_proj.bias', 'module.transformer.h.8.ln_2.weight', 'module.transformer.h.8.ln_2.bias', 'module.transformer.h.8.mlp.c_fc.weight', 'module.transformer.h.8.mlp.c_fc.bias', 'module.transformer.h.8.mlp.c_proj.weight', 'module.transformer.h.8.mlp.c_proj.bias', 'module.transformer.h.9.ln_1.weight', 'module.transformer.h.9.ln_1.bias', 'module.transformer.h.9.attn.bias', 'module.transformer.h.9.attn.masked_bias', 'module.transformer.h.9.attn.c_attn.weight', 'module.transformer.h.9.attn.c_attn.bias', 'module.transformer.h.9.attn.c_proj.weight', 'module.transformer.h.9.attn.c_proj.bias', 'module.transformer.h.9.ln_2.weight', 'module.transformer.h.9.ln_2.bias', 'module.transformer.h.9.mlp.c_fc.weight', 'module.transformer.h.9.mlp.c_fc.bias', 'module.transformer.h.9.mlp.c_proj.weight', 'module.transformer.h.9.mlp.c_proj.bias', 'module.transformer.h.10.ln_1.weight', 'module.transformer.h.10.ln_1.bias', 'module.transformer.h.10.attn.bias', 'module.transformer.h.10.attn.masked_bias', 'module.transformer.h.10.attn.c_attn.weight', 'module.transformer.h.10.attn.c_attn.bias', 'module.transformer.h.10.attn.c_proj.weight', 'module.transformer.h.10.attn.c_proj.bias', 'module.transformer.h.10.ln_2.weight', 'module.transformer.h.10.ln_2.bias', 'module.transformer.h.10.mlp.c_fc.weight', 'module.transformer.h.10.mlp.c_fc.bias', 'module.transformer.h.10.mlp.c_proj.weight', 'module.transformer.h.10.mlp.c_proj.bias', 'module.transformer.h.11.ln_1.weight', 'module.transformer.h.11.ln_1.bias', 'module.transformer.h.11.attn.bias', 'module.transformer.h.11.attn.masked_bias', 'module.transformer.h.11.attn.c_attn.weight', 'module.transformer.h.11.attn.c_attn.bias', 'module.transformer.h.11.attn.c_proj.weight', 'module.transformer.h.11.attn.c_proj.bias', 'module.transformer.h.11.ln_2.weight', 'module.transformer.h.11.ln_2.bias', 'module.transformer.h.11.mlp.c_fc.weight', 'module.transformer.h.11.mlp.c_fc.bias', 'module.transformer.h.11.mlp.c_proj.weight', 'module.transformer.h.11.mlp.c_proj.bias', 'module.transformer.ln_f.weight', 'module.transformer.ln_f.bias', 'module.lm_head.weight'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ckpt.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "def check_for_weight_keys(ckpt):\n",
    "    new_state_dict = OrderedDict()\n",
    "    for k, v in ckpt.items():\n",
    "        if k[:6] == 'module':               \n",
    "            name = k[7:] # remove `module.`\n",
    "        else:\n",
    "            name = k\n",
    "        new_state_dict[name] = v\n",
    "    return new_state_dict\n",
    "\n",
    "ckpt = check_for_weight_keys(ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt2.load_state_dict(ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2 = transformers.AutoModelForCausalLM.from_config(config).load_state_dict(ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2Config {\n",
       "  \"_name_or_path\": \"gpt2\",\n",
       "  \"activation_function\": \"gelu_new\",\n",
       "  \"architectures\": [\n",
       "    \"GPT2LMHeadModel\"\n",
       "  ],\n",
       "  \"attn_pdrop\": 0.1,\n",
       "  \"bos_token_id\": 50256,\n",
       "  \"embd_pdrop\": 0.1,\n",
       "  \"eos_token_id\": 50256,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"layer_norm_epsilon\": 1e-05,\n",
       "  \"model_type\": \"gpt2\",\n",
       "  \"n_ctx\": 1024,\n",
       "  \"n_embd\": 768,\n",
       "  \"n_head\": 12,\n",
       "  \"n_inner\": null,\n",
       "  \"n_layer\": 12,\n",
       "  \"n_positions\": 1024,\n",
       "  \"pad_token_id\": 1,\n",
       "  \"reorder_and_upcast_attn\": false,\n",
       "  \"resid_pdrop\": 0.1,\n",
       "  \"scale_attn_by_inverse_layer_idx\": false,\n",
       "  \"scale_attn_weights\": true,\n",
       "  \"summary_activation\": null,\n",
       "  \"summary_first_dropout\": 0.1,\n",
       "  \"summary_proj_to_labels\": true,\n",
       "  \"summary_type\": \"cls_index\",\n",
       "  \"summary_use_proj\": true,\n",
       "  \"task_specific_params\": {\n",
       "    \"text-generation\": {\n",
       "      \"do_sample\": true,\n",
       "      \"max_length\": 50\n",
       "    }\n",
       "  },\n",
       "  \"transformers_version\": \"4.25.1\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 50277\n",
       "}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.bos_token_id = 2\n",
    "config.eos_token_id = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2.config = config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2 = transformers.AutoModelForCausalLM.from_config(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt2.load_state_dict(ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2.config = config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-19 10:57:26.352721: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-19 10:57:26.856987: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11/lib64:\n",
      "2023-03-19 10:57:26.857078: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-11/lib64:\n",
      "2023-03-19 10:57:26.857084: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "tokenizer = transformers.PreTrainedTokenizerFast(tokenizer_file='./lm_eval/20B_tokenizer.json')\n",
    "tokenizer.pad_token_id = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizerFast(name_or_path='', vocab_size=50254, model_max_len=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'pad_token': '<|padding|>'})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a0d390687cd339eb953412a1fc63e66b8089e403a3a66fa9772386419ead3bc2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
